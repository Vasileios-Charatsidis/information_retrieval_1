{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Autors: \n",
    "* Dana Kianfar - 11391014\n",
    "* Jose Gallego - 11390689\n",
    "\n",
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goal of this assignment was to implement and compare the performance of several approaches to the Learning to Rank (LTR) problem. We received an implementation of a pointwise method base on squared-loss minimization and implemented RankNet (pairwise) and LambdaNet (listwise) algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodology\n",
    "\n",
    "The training of the methods was executed on a database with 5 cross-validation folds, each containing the 90 training, 30 validation and 30 test examples with no overlap. The dataset is constructed for a homepage finding task, therefore each query should have exactly one relevant document label. Initial data exploration indicated that some queries were noisy as they had zero or more than one relevant document labels. We took these cases into consideration in our implementation.\n",
    "\n",
    "For each algorithm, we obtained results on all 5 folds of the data where we trained a model on the training data for 200 epochs and reported the objective function evaluation, training mNDCG, and validation mNDCG for each epoch. After training on all folds of the dataset, we obtained five candidate models for each algorithm. For each algorithm we then chose a top candidate according to its validation mNDCG at the end of 200 epochs. For all three algorithms, fold 3 provided the best validation mNDCG. We used the top candidate to report the test mNDCG on the fold it was obtained from, which is fold 3.\n",
    "\n",
    "We used L1 and L2 regularization using the default assignment values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pointwise MSE\n",
    "\n",
    "As our dataset is heavily unbalanced, with approximately one positive label per query, we did not expect to achieve reasonable mNDCG results from this algorithm. This is due to the fact that a point-wise approach does not take the ranking structure into account, and the training involves a squared-loss function instead of an IR metric directly.\n",
    "\n",
    "![Figure 1. Pointwise method training loss for each fold](img/pointwise_train_loss.png)\n",
    "\n",
    "![Figure 2. Pointwise method training mNDCG for each fold](img/pointwise_train_mndcg.png)\n",
    " \n",
    "![Figure 3. Pointwise method validation mNDCG for each fold](img/pointwise_val_mndcg.png)\n",
    " \n",
    " The training algorithm displays good behavior, with a high error function drop in the initial epochs and a relatively low convergence after iteration 50. There is also a decrease in the variance of the errors across folds over time. This might configure a overfitting scenario in terms of the training error. However, the fact that the objective function and the mNDCG are not directly coupled by the training scheme does not induce _perfect_ mNDCG values on the training data, as can be seen in Figure 2. Besides, there variance on the mNDCG obtained on the training and validation sets is low across folds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pairwise RankNet\n",
    "\n",
    "We took advantage of the sparsity of the $S$ matrix used in RankNet and LambdaNet to improve the runtimes of our algorithms. We computed the $S$ matrix for each query in the training and validation set for each fold in advance, to reduce overhead. Given the extremely low number of relevant labels per query, each $S$ matrix is very sparse and can be computed and stored efficiently. Besides, we decided to use $\\sigma = 1$ for mathematical simplicity on RankNet and LambdaRank. \n",
    "\n",
    "![Figure 4. Pairwise method utility for each fold](img/pairwise_train_loss.png)\n",
    "\n",
    "![Figure 5. Pairwise method training mNDCG for each fold](img/pairwise_train_mndcg.png)\n",
    " \n",
    "![Figure 6. Pairwise method validation mNDCG for each fold](img/pairwise_val_mndcg.png)\n",
    "\n",
    " \n",
    "For this model, we see a clear overfitting trend. The training utility flattens around 50 iterations for all folds, however the corresponding mNDCG values increase until around iteration 200 but the validation mNDCG values have an almost monotonously decreasing behaviour. The results confirm the effectiveness of the introduction of the $\\lambda$s as an strategy to learn ranking structures (reflected on a much better training and validation mNDCG) and to alleviate the imbalanced-data problem. In this case, the model with the best mNDCG was found at epoch 30 on fold 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listwise LambdaNet\n",
    "\n",
    "Note that the calculation of $|\\Delta NDCG|$ can be simplified from calculating NDCG twice to only considering the discounted gain that each of the swapped documents generates. Let's assume that we have a ranking in which the documents at position $i$ and $j$ are to be interchanged:\n",
    "\n",
    "$$ R1 = [ 1, 2, 3, \\ldots, i, \\ldots, j, \\ldots, 1000]$$\n",
    "$$ \\, \\, \\,\\, \\, \\,\\, \\, \\,\\, \\, \\,\\, \\, \\,\\,  \\uparrow \\_\\_ \\uparrow$$\n",
    "\n",
    "This generates the ranking:\n",
    "$$ R2 = [ 1, 2, 3, \\ldots, j, \\ldots, i, \\ldots, 1000]$$\n",
    "\n",
    "Thus, calculating the $|\\Delta NDCG|$ is equivalent to:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\Delta NDCG &=& \\left|NDCG(R2) - NDCG(R1) \\right| \\\\\n",
    "&=& \\left| \\left[ \\sum_{k \\ne i,j} \\frac{2^{rel_k} -1 }{\\log(1+k)} + \\frac{2^{rel_i} - 1 }{\\log(1+j)} + \\frac{2^{rel_j} -1 }{\\log(1+i)} \\right] - \\left[ \\sum_{k \\ne i,j} \\frac{2^{rel_k} -1 }{\\log(1+k)} + \\frac{2^{rel_i} - 1 }{\\log(1+i)} + \\frac{2^{rel_j} -1 }{\\log(1+j)} \\right] \\right| \\\\\n",
    "&=& \\left|\\left( 2^{rel_i} - 2^{rel_j} \\right) \\left( \\frac{1}{\\log(1+j)} - \\frac{1}{\\log(1+i)}\\right) \\right|\n",
    "\\end{eqnarray*}\n",
    "\n",
    "![Figure 7. Listwise method utility for each fold](img/listwise_train_loss.png)\n",
    "\n",
    "![Figure 8. Listwise method training mNDCG for each fold](img/listwise_train_mndcg.png)\n",
    " \n",
    "![Figure 9. Listwise method validation mNDCG for each fold](img/listwise_val_mndcg.png)\n",
    " \n",
    " The behavior of this model is very similar to the one observed in RankNet. There is a good performance on the training mNDCG, however the advantage of introducing the $|\\Delta NDCG|$ factor in the computation on $\\lambda$ is not very noticeable. This might be due to the presence of only one relevant document per query. As well as the pairwise method, the best validation mNDCG was found on fold 3, around 30 iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison\n",
    "\n",
    "We compare the three algorithms by their training and validation mNDCG across all 5 folds on 200 epochs. We display their learning curves below, and for each algorithm summarize the training and validation mNDCG to provide a concise plot. The variance across the folds is displayed by the vertical bars which represent their 95% confidence intervals.\n",
    "\n",
    "![Figure 10. Pointwise method training average mNDCG across folds](img/pointwise_mean_train_val.png)\n",
    " \n",
    "We observe in Figure 10 that both training and validation mNDCG scores for the pointwise algorithm converge around epoch 50. The best ranker for this algorithm was trained after 50 epochs on fold 3 with a validation mNDCG of 0.72. We selected this ranker to report the test score on the same fold. It achieved a test mNDCG of 0.77.\n",
    " \n",
    "![Figure 11. Pairwise method training average mNDCG across folds](img/pairwise_mean_train_val.png)\n",
    " \n",
    "In Figure 11, we see that both training and validation mNDCG scores for the pairwise algorithm converge around epoch 30. The best ranker for this algorithm was trained after 30 epochs on fold 3 with a validation mNDCG of 0.84. This ranker obtained a test mNDCG of 0.89 on the same fold.\n",
    " \n",
    "![Figure 12. Listwise method training average mNDCG across folds](img/listwise_mean_train_val.png)\n",
    "\n",
    " \n",
    "We observe in Figure 12 that both training and validation mNDCG scores for the listwise algorithm converge around epoch 30. The best ranker for this algorithm was trained after 30 epochs on fold 3 with a validation mNDCG of 0.87. This ranker obtained a test mNDCG of 0.91 on the same fold.\n",
    "\n",
    "Overall, the pairwise and listwise methods achieve a better validation mNDCG than the pointwise method. The listwise method achieves a slightly higher validation mNDCG than the pairwise.\n",
    " \n",
    "## Statistical tests\n",
    "\n",
    "Before conducting our experiments we expected both pairwise and listwise methods to outperform the pointwise method due to reasons discussed previously; namely that a pointwise approach is ill-suited for the heavily skewed distribution of labels, and moreover the ranking structures are invisible to the squared-loss gradient descent optimizer. As all three methods obtained their best rankers on fold 3, we were able to perform one-sided sign-binomial 30-sample tests  on the NDCG of each test query. We conducted a total of three tests, where we compared both pairwise and listwise algorithms against pointwise, and listwise against pairwise. We excluded queries where any two paired algorithm's NDCG values tied.\n",
    "\n",
    "\n",
    "| Algorithm | Best fold | Validation mNDCG | Test mNDCG |    \n",
    "| :-: | :-: | :-: | :-: |\n",
    "|Pointwise| 3 | 0.72 | 0.77 |\n",
    "|Pairwise| 3  | 0.84 | 0.89 |\n",
    "|Listwise| 3  | 0.87 | 0.91 |\n",
    "\n",
    "##### Pairwise vs Pointwise\n",
    "As expected, the null hypothesis was rejected in favor of the pairwise algorithm with a p-value of 0.01.\n",
    "\n",
    "##### Listwise vs Pointwise\n",
    "The null hypothesis was rejected in favor of the listwise algorithm with a p-value of 0.0002.\n",
    "\n",
    "##### Listwise vs Pairwise\n",
    "There was not sufficient evidence to reject the null hypothesis in this test, where we obtained a p-value of 0.63. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

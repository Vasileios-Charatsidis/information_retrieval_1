{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning to Rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goal of this assignment was to implement and compare the performance of several approaches to the Learning to Rank (LTR) problem. We received an implementation of a pointwise method base on squared-loss minimization and implemented RankNet (pairwise) and LambdaNet (listwise) algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "The training of the methods was executed on a database with 5 cross-validation folds, each containing the 90 training, 30 validation and 30 test examples with no overlap. The dataset is constructed fora homepage finding task, therefore each query should have exactly one relevant document label. Initial data exploration indicated that some queries were noisy as they had zero or more than one relevant document labels. We took these cases into consideration in our implementation.\n",
    "\n",
    "For each algorithm, we obtained results on all 5 folds of the data where we trained a model on the training data for 200 epochs and reported the objective function evaluation, training mNDCG, and validation mNDCG for each epoch. Across all folds of the dataset, we obtained five candidate models for each algorithm. For each algorithm we then chose a top candidate according to its validation mNDCG on the final training epoch. We used the top candidate to report the test mNDCG on all test data (obtained from the five folds).\n",
    "\n",
    "We used L1 and L2 regularization using the default assignment values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pointwise MSE\n",
    "\n",
    "As our dataset is heavily unbalanced, with approximately one positive label per query, we did not expect to achieve reasonable mNDCG results from this algorithm. This is due to the fact that a point-wise approach does not take the ranking structure into account, and the training involves a squared-loss function instead of an IR metric directly.\n",
    "\n",
    "![pointwise_train_loss](img/pointwise_train_loss.png)\n",
    "\n",
    "<font size=\"3.5\"> <center> <b> Figure 1. Pointwise method training loss for each fold </b> </center> \n",
    " </font>\n",
    "\n",
    "![pointwise_train_mndcg](img/pointwise_train_mndcg.png)\n",
    "\n",
    "<font size=\"3.5\"> <center> <b> Figure 2. Pointwise method training mNDCG for each fold </b> </center> \n",
    " </font>\n",
    " \n",
    "![pointwise_val_mndcg](img/pointwise_val_mndcg.png)\n",
    "\n",
    "<font size=\"3.5\"> <center> <b> Figure 3. Pointwise method validation mNDCG for each fold </b> </center> \n",
    " </font>\n",
    " \n",
    " The training algorithm displays good behavior, with a high error function drop in the initial epochs and a relatively low convergence after iteration 50. There is also a decrease in the variance of the errors across folds over time. This might configure a overfitting scenario in terms of the training error, but, as can be seen in Figure 2, the fact that the objective function and the mNDCG are not directly coupled by the training scheme does not induce _perfect_ mNDCG values on the training data. Besides, there variance on the mNDCG obtained on the training and validation sets is low across folds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairwise RankNet\n",
    "\n",
    "We took advantage of the sparsity of the $S$ matrix used in RankNet and LambdaNet to improve the runtimes of our algorithms. We computed the $S$ matrix for each query in the training and validation set for each fold in advance, to reduce overhead. Given the extremely low number of relevant labels per query, each $S$ matrix is very sparse and can be computed and stored efficiently. \n",
    "\n",
    "![pairwise_train_loss2](img/pairwise_train_loss.png)\n",
    "\n",
    "<font size=\"3.5\"> <center> <b> Figure 4. Pairwise method utility for each fold </b> </center> \n",
    " </font>\n",
    "\n",
    "![pairwise_train_mndcg](img/pairwise_train_mndcg.png)\n",
    "\n",
    "<font size=\"3.5\"> <center> <b> Figure 5. Pairwise method training mNDCG for each fold </b> </center> \n",
    " </font>\n",
    " \n",
    "![pairwise_val_mndcg](img/pairwise_val_mndcg.png)\n",
    "\n",
    "<font size=\"3.5\"> <center> <b> Figure 6. Pairwise method validation mNDCG for each fold </b> </center> \n",
    " </font>\n",
    " \n",
    "For this model, we see a clear overfitting trend. The training utility flattens around 50 iterations for all folds, however the corresponding mNDCG values increase until around iteration 200 but the validation mNDCG values have an almost monotonously decreasing behaviour. The results confirm the effectiveness of the introduction of the $\\lambda$s as an strategy to learn ranking structures (reflected on a much better training and validation mNDCG) and to alleviate the imbalanced-data problem. In this case, the model with the best mNDCG was found at epoch 30 on fold 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listwise LambdaNet\n",
    "\n",
    "Note that the calculation of $|\\Delta NDCG|$ can be simplified from calculating NDCG twice to only considering the discounted gain that each of the swapped documents generates. Let's assume that we have a ranking in which the documents at position $i$ and $j$ are to be interchanged:\n",
    "\n",
    "$$ R1 = [ 1, 2, 3, \\ldots, i, \\ldots, j, \\ldots, 1000]$$\n",
    "$$ \\, \\, \\,\\, \\, \\,\\, \\, \\,\\, \\, \\,\\, \\, \\,\\,  \\uparrow \\_\\_ \\uparrow$$\n",
    "\n",
    "This generates the ranking:\n",
    "$$ R2 = [ 1, 2, 3, \\ldots, j, \\ldots, i, \\ldots, 1000]$$\n",
    "\n",
    "Thus, calculating the $|\\Delta NDCG|$ is equivalent to:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\Delta NDCG &=& \\left|NDCG(R2) - NDCG(R1) \\right| \\\\\n",
    "&=& \\left| \\left[ \\sum_{k \\ne i,j} \\frac{2^{rel_k} -1 }{\\log(1+k)} + \\frac{2^{rel_i} - 1 }{\\log(1+j)} + \\frac{2^{rel_j} -1 }{\\log(1+i)} \\right] - \\left[ \\sum_{k \\ne i,j} \\frac{2^{rel_k} -1 }{\\log(1+k)} + \\frac{2^{rel_i} - 1 }{\\log(1+i)} + \\frac{2^{rel_j} -1 }{\\log(1+j)} \\right] \\right| \\\\\n",
    "&=& \\left|\\left( 2^{rel_i} - 2^{rel_j} \\right) \\left( \\frac{1}{\\log(1+j)} - \\frac{1}{\\log(1+i)}\\right) \\right|\n",
    "\\end{eqnarray}\n",
    "\n",
    "\n",
    "\n",
    "![listwise_train_loss](img/listwise_train_loss.png)\n",
    "\n",
    "<font size=\"3.5\"> <center> <b> Figure 7. Listwise method utility for each fold </b> </center> \n",
    " </font>\n",
    " \n",
    "![listwise_train_mndcg](img/listwise_train_mndcg.png)\n",
    "\n",
    "<font size=\"3.5\"> <center> <b> Figure 8. Listwise method training mNDCG for each fold </b> </center> \n",
    " </font>\n",
    " \n",
    "![listwise_val_mndcg](img/listwise_val_mndcg.png)\n",
    "\n",
    "<font size=\"3.5\"> <center> <b> Figure 9. Listwise method validation mNDCG for each fold </b> </center> \n",
    " </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison\n",
    "\n",
    "![pointwise_mean_train_val](img/pointwise_mean_train_val.png)\n",
    "\n",
    "\n",
    "<font size=\"3.5\"> <center> <b> Figure 10. Pointwise method training average mNDCG across folds </b> </center> \n",
    " </font>\n",
    " \n",
    "![pairwise_mean_train_val](img/pairwise_mean_train_val.png)\n",
    "\n",
    "\n",
    "<font size=\"3.5\"> <center> <b> Figure 11. Pairwise method training average mNDCG across folds </b> </center> \n",
    " </font>\n",
    " \n",
    "![listwise_mean_train_val](img/listwise_mean_train_val.png)\n",
    "\n",
    "<font size=\"3.5\"> <center> <b> Figure 12. Listwise method training average mNDCG across folds </b> </center> \n",
    " </font>\n",
    " \n",
    "Statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
